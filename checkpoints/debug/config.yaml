algorithm_path: agents.dgn.DGNAgent
base_config:
- ./env.yaml
- configs/base_configs/dgn.yaml
batch_size: 128
buffer_capacity: 50000
burnin_episode: 1000
env_comm_range: 3
env_max_food: 10
env_num_agent: 100
env_num_grid: 32
env_obs_range: 1
episode_length: 500
epsilon_decay_percent_episode: 2.0e-05
epsilon_decay_temperature: 0.0001
epsilon_exponential_decay: true
epsilon_linear_decay: false
gamma: 0.95
hidden_dim: 256
initial_epsilon: 0.9
learning_rate: 0.001
min_epsilon: 0.3
num_episodes: 20000
num_head: 4
num_max_keep_ckpt: 5
scenario_path: scenarios.surviving.Surviving
skip_connect: true
soft_update_target_network: false
tau: 0.99
testing_action_mode: epsilon-greedy
testing_episodes: 20
testing_interval: 100
trainer_path: trainers.value_based_trainer.ValueBasedTrainer
training_action_mode: epsilon-greedy
training_interval: 1
training_times: 20
work_dir: checkpoints/debug
